{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/c-w-m/anlp-tf2/blob/master/chapter5-nlg-with-transformer-gpt/text-generation-with-GPT-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:53:38.862963Z",
     "start_time": "2020-10-01T21:53:37.344493Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__\n",
    "\n",
    "tf.random.set_seed(42)  # for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:53:40.265307Z",
     "start_time": "2020-10-01T21:53:38.891217Z"
    }
   },
   "outputs": [],
   "source": [
    "######## GPU CONFIGS FOR RTX 2070 ###############\n",
    "## Please ignore if not training on GPU       ##\n",
    "## this is important for running CuDNN on GPU ##\n",
    "\n",
    "tf.keras.backend.clear_session() #- for easy reset of notebook state\n",
    "\n",
    "# chck if GPU can be seen by TF\n",
    "tf.config.list_physical_devices('GPU')\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:53:41.277751Z",
     "start_time": "2020-10-01T21:53:40.514853Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFOpenAIGPTLMHeadModel, OpenAIGPTTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:53:46.161388Z",
     "start_time": "2020-10-01T21:53:42.619559Z"
    }
   },
   "outputs": [],
   "source": [
    "gpttokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "gpt = TFOpenAIGPTLMHeadModel.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:54:50.685322Z",
     "start_time": "2020-10-01T21:54:38.240472Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = gpttokenizer.encode('Robotics is the ', return_tensors='tf')\n",
    "print(input_ids)\n",
    "greedy_output = gpt.generate(input_ids, max_length=100)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(gpttokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:55:16.061027Z",
     "start_time": "2020-10-01T21:55:13.333259Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "gpt2tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "gpt2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", \n",
    "                                         pad_token_id=gpt2tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:55:23.517246Z",
     "start_time": "2020-10-01T21:55:17.435194Z"
    }
   },
   "outputs": [],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = gpt2tokenizer.encode('Robotics is the ', return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = gpt2.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:55:35.102811Z",
     "start_time": "2020-10-01T21:55:27.887836Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # for reproducible results\n",
    "# BEAM SEARCH\n",
    "# activate beam search and early_stopping\n",
    "beam_output = gpt2.generate(\n",
    "    input_ids, \n",
    "    max_length=51, \n",
    "    num_beams=20, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:55:51.708801Z",
     "start_time": "2020-10-01T21:55:41.049036Z"
    }
   },
   "outputs": [],
   "source": [
    "# set no_repeat_ngram_size to 3\n",
    "beam_output = gpt2.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=3, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:56:18.662519Z",
     "start_time": "2020-10-01T21:56:06.291288Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Returning multiple beams\n",
    "tf.random.set_seed(42)  # for reproducible results\n",
    "beam_outputs = gpt2.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=7, \n",
    "    no_repeat_ngram_size=3, \n",
    "    num_return_sequences=3,  \n",
    "    early_stopping=True,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"\\n{}: {}\".format(i, \n",
    "                        gpt2tokenizer.decode(beam_output, \n",
    "                                             skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:56:37.968897Z",
     "start_time": "2020-10-01T21:56:31.887781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Top-K sampling\n",
    "tf.random.set_seed(42)  # for reproducible results\n",
    "beam_output = gpt2.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    do_sample=True, \n",
    "    top_k=25,\n",
    "    temperature=2\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:57:44.012864Z",
     "start_time": "2020-10-01T21:57:18.453191Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = gpt2tokenizer.encode('In the dark of the night, there was a ', return_tensors='tf')\n",
    "# Top-K sampling\n",
    "tf.random.set_seed(42)  # for reproducible results\n",
    "beam_output = gpt2.generate(\n",
    "    input_ids, \n",
    "    max_length=200, \n",
    "    do_sample=True, \n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:57:53.136325Z",
     "start_time": "2020-10-01T21:57:44.063001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Another sample with a larger model\n",
    "gpt2tok_l = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "gpt2_l = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", \n",
    "                                         pad_token_id=gpt2tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T21:59:04.169629Z",
     "start_time": "2020-10-01T21:57:53.178268Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = gpt2tok_l.encode('In the dark of the night, there was a ', return_tensors='tf')\n",
    "# Top-K sampling\n",
    "tf.random.set_seed(42)  # for reproducible results\n",
    "beam_output = gpt2_l.generate(\n",
    "    input_ids, \n",
    "    max_length=200, \n",
    "    do_sample=True, \n",
    "    top_k=25\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 50 * '-')\n",
    "print(gpt2tok_l.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp37",
   "language": "python",
   "name": "anlp37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "366px",
    "left": "1112px",
    "right": "20px",
    "top": "120px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
